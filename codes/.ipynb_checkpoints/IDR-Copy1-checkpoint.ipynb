{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c85750e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import glob\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b50758c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# High_AUC_PPV_FUNCTIONS = pd.read_csv(\"High_AUC_PPV_FUNCTIONS.txt\", sep=\"\\t\")\n",
    "# High_AUC_PPV_FUNCTIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c2e0f41d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Top_148_test_union_function_groups = pd.read_csv(\"Top_148_test_union_function_groups.txt\", sep=\"\\t\")\n",
    "# Top_148_test_union_function_groups"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86e1562d",
   "metadata": {},
   "source": [
    "### If needed, remember to change the permission of files and folders"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abe952b8",
   "metadata": {},
   "source": [
    "## Protein file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a9852a7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_protein_filter_list(protein_file_name):\n",
    "    protein_df = pd.read_csv(protein_file_name,  names = [\"Protein_name\",\"Score\"], header=0, index_col=0)\n",
    "    # protein_filter = protein_df[protein_df['Score'] > protein_cutoff_value]\n",
    "    \n",
    "    # choose top 20 proteins in each pred file\n",
    "    protein_df[\"Rank\"] = protein_df[\"Score\"].rank(ascending=False) \n",
    "    protein_df = protein_df.sort_values(\"Rank\")\n",
    "    protein_filter = protein_df.head(20)\n",
    "    return protein_filter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cdbdb7c",
   "metadata": {},
   "source": [
    "### In the protein file, max = 0.25, see the question from email"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81c95af5",
   "metadata": {},
   "source": [
    "## IDR file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "15e1ad92",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_IDR_num(filter_IDRs):\n",
    "    count_dict = dict()\n",
    "    for ID in filter_IDRs[\"UniProtID\"]:\n",
    "        if ID in count_dict:\n",
    "            count_dict[ID] += 1\n",
    "        else:\n",
    "            count_dict[ID] = 1\n",
    "\n",
    "    count_list = []\n",
    "    for ID in filter_IDRs[\"UniProtID\"]:\n",
    "        if ID in count_dict:\n",
    "            count_list.append(count_dict.get(ID))\n",
    "    filter_IDRs[\"The number of IDRs in each protein\"] = count_list\n",
    "    return count_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "59671f50",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_protein_name(query):\n",
    "    base_url = \"https://www.ebi.ac.uk/proteins/api/{}\"\n",
    "    url = base_url.format(query)\n",
    "#     print(\"URL:\", url)\n",
    "    \n",
    "    try:\n",
    "        response = requests.get(url, headers={ \"Accept\" : \"application/json\"})\n",
    "#         print(\"Status code:\", response.raise_for_status())  # Check for errors: None == 200\n",
    "        \n",
    "        data_list = response.json()\n",
    "#         print(type(data_list))\n",
    "        data_dict = data_list[0]\n",
    "#         print(type(data_dict))\n",
    "        \n",
    "        protein_name = data_dict.get('protein').get('recommendedName').get('fullName').get('value')\n",
    "        return protein_name\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(\"Error:\", e)\n",
    "        return None\n",
    "\n",
    "def get_protein_name_list(uniprot_id_list):\n",
    "    protein_name_list = []\n",
    "    for uniprot_id in uniprot_id_list:\n",
    "        query = \"proteins?offset=0&accession=\" + uniprot_id\n",
    "        protein_name = get_protein_name(query)\n",
    "        protein_name_list.append(protein_name)\n",
    "    return protein_name_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dc4ed4f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://plotly.com/python/v3/html-reports/#generate-html-reports-with-d3-graphsusing-python-plotly-and-pandas\n",
    "def create_IDR_filter_list(IDR_file_name, IDR_cutoff_value1, IDR_cutoff_value2, filtered_protein_name):\n",
    "    IDR_df = pd.read_csv(IDR_file_name, names = [\"Protein IDR\",\"Score\"], header=0)\n",
    "    \n",
    "    # Split GO_term string in order to let user understand the meaning of each column\n",
    "    # https://stackoverflow.com/questions/14745022/how-to-split-a-dataframe-string-column-into-two-columns\n",
    "    # n=the number of columns you expect\n",
    "    IDR_df[['UniProtID', 'Redundancy', 'Begin', 'End']] = IDR_df['Protein IDR'].str.split('_', n=4, expand=True)\n",
    "    \n",
    "    # combine the \"beginning position\" and \"end position\" columns\n",
    "    IDR_df[\"The beginning and ending positions of IDR\"] = IDR_df['Begin'].astype(str) +\"-\"+ IDR_df[\"End\"]\n",
    "    \n",
    "    \n",
    "    filter_IDRs = pd.DataFrame()\n",
    "    for p_name in filtered_protein_name:\n",
    "        for IDR_name in IDR_df[\"Protein IDR\"].values:\n",
    "            if p_name in IDR_name:\n",
    "                s2 = IDR_df[IDR_df[\"Protein IDR\"] == IDR_name]\n",
    "                filter_IDRs = pd.concat([filter_IDRs, s2], ignore_index=True)\n",
    "                \n",
    "    # compute the total numbe of IDRs in each protein            \n",
    "    count_list = compute_IDR_num(filter_IDRs)\n",
    "    filter_IDRs[\"The number of IDRs in each protein\"] = count_list\n",
    "    \n",
    "    # remove all IDRs whose score <= 0.5\n",
    "    filter_IDRs = filter_IDRs[filter_IDRs[\"Score\"] > IDR_cutoff_value1]\n",
    "    \n",
    "    # remove useless columns\n",
    "    filter_IDRs = filter_IDRs.drop(columns=['Protein IDR', 'Redundancy', 'Begin', 'End'])\n",
    "    \n",
    "    # rename columns in order to make them more understandable\n",
    "    filter_IDRs = filter_IDRs[['UniProtID', 'The beginning and ending positions of IDR', 'Score', 'The number of IDRs in each protein']]\n",
    "    \n",
    "    # if the protein has more than 2 IDRs, remove IDRs whose score <= 0.6\n",
    "    temp_df = filter_IDRs[filter_IDRs[\"The number of IDRs in each protein\"]>2]\n",
    "    filter_IDRs = filter_IDRs.drop((temp_df[\"Score\"] < 0.6).index.values)\n",
    "    \n",
    "    # hold two digits after the decimal points\n",
    "#     filter_IDRs[\"Score\"] = filter_IDRs[\"Score\"].astype(float)\n",
    "#     filter_IDRs[\"Score\"] = filter_IDRs[\"Score\"].round(2)\n",
    "    \n",
    "    # rename \"Score\"\n",
    "#     filter_IDRs = filter_IDRs.rename(columns={\"Score\": \"The probability of the association between the IDR and the function\"})\n",
    "    \n",
    "    # remove the \"Score\" column since their probabilities are amostly 1, so not very informative/interesting\n",
    "    filter_IDRs = filter_IDRs.drop(columns=['Score'])\n",
    "    \n",
    "    # add protein name column\n",
    "    uniprot_id_list = filter_IDRs[\"UniProtID\"]\n",
    "    protein_name_list = get_protein_name_list(uniprot_id_list)\n",
    "    filter_IDRs.insert(1, \"Protein name\", protein_name_list)\n",
    "\n",
    "    html_filter_IDRs = filter_IDRs.to_html(index=False).replace('<table border=\"1\" class=\"dataframe\">','<table class=\"table table-striped\">')\n",
    "    html_filter_IDRs = html_filter_IDRs.replace('<td>', '<td style=\"text-align: center;\">') # center text\n",
    "    html_filter_IDRs= html_filter_IDRs.replace('<th>', '<th style=\"text-align: center;\">') # center column names\n",
    "    return html_filter_IDRs "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3269fae0",
   "metadata": {},
   "source": [
    "## Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "44e6b474",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_feature_filter_list(feature_file_name):\n",
    "    feature_df = pd.read_csv(feature_file_name, names = [\"Feature name\",\"Score\"])\n",
    "    filter_features = feature_df.dropna()\n",
    "    \n",
    "    # hold two digits after the decimal points\n",
    "    filter_features[\"Score\"] = filter_features[\"Score\"].astype(float)\n",
    "    filter_features[\"Score\"] = filter_features[\"Score\"].round(2)\n",
    "    \n",
    "    # rename \"Score\"\n",
    "    filter_features = filter_features.rename(columns={\"Score\": \"The strength and direction of association with function for each molecular feature\"})    \n",
    "    \n",
    "    html_filter_features = filter_features.to_html(index=False).replace('<table border=\"1\" class=\"dataframe\">','<table class=\"table table-striped\">')\n",
    "    html_filter_features = html_filter_features.replace('<td>', '<td style=\"text-align: center;\">') # center text\n",
    "    html_filter_features = html_filter_features.replace('<th>', '<th style=\"text-align: center;\">') # center column names\n",
    "    return html_filter_features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82010c5f",
   "metadata": {},
   "source": [
    "## HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2f2152b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# refer to https://plotly.com/python/v3/html-reports/#generate-html-reports-with-d3-graphsusing-python-plotly-and-pandas\n",
    "def convert_to_HTML_format(filter_IDRs, filter_features, function_name):\n",
    "    html_string = '''\n",
    "    <html>\n",
    "        <head>\n",
    "            <link rel=\"stylesheet\" href=\"https://maxcdn.bootstrapcdn.com/bootstrap/3.3.1/css/bootstrap.min.css\">\n",
    "            <style>body{ margin:0 100; background:whitesmoke; }</style>\n",
    "            \n",
    "            <script> \n",
    "                window.addEventListener('DOMContentLoaded', (event) => {\n",
    "                    // Get all the cells in the first column of the IDRs List table\n",
    "                    const cells = document.querySelectorAll('table.table-striped:nth-of-type(1) td:nth-child(1)');\n",
    "\n",
    "                    // Add a hyperlink to each cell\n",
    "                    cells.forEach((cell) => {\n",
    "                        const text = cell.innerText;\n",
    "                        console.log(text)\n",
    "                        const hyperlink = document.createElement('a');\n",
    "                        hyperlink.href = \"https://www.uniprot.org/uniprotkb/\" + text + \"/entry\" + text; //add URL\n",
    "                        hyperlink.textContent = text;\n",
    "                        cell.innerText = '';\n",
    "                        cell.appendChild(hyperlink);\n",
    "                    });    \n",
    "                });\n",
    "            </script>\n",
    "            \n",
    "        </head>\n",
    "        <body>\n",
    "            <h1>Group/Function: ''' + function_name.split(\"/\")[-1] + '''</h1>\n",
    "\n",
    "            <!-- *** Two Lists *** --->\n",
    "            <h2>IDRs List</h2>\n",
    "            ''' + filter_IDRs + '''\n",
    "\n",
    "            <h2>Features List</h2>\n",
    "            <p><a href=\"http://142.150.219.123:5000/table/\">Molecular Features Table</a></p>\n",
    "            ''' + filter_features + '''\n",
    "        </body>\n",
    "    </html>'''\n",
    "    \n",
    "    function_name = function_name.split(\"/\")[-1]\n",
    "    open_path = f'../webpages/{function_name}.html' # put a variable within a string\n",
    "    f = open(open_path,'w')\n",
    "    f.write(html_string)\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2990f445",
   "metadata": {},
   "source": [
    "* Note:\n",
    "If get rid of \"=>\" in the line \"cells.forEach((cell) => {...\", resulting in the hyperlinks do not work"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f42a22a",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59d03380",
   "metadata": {},
   "source": [
    "## Automatically read each csv file in one folder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8684dd1",
   "metadata": {},
   "source": [
    "### There is huge differences between using severl \"if\" and \"if, elif, else\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "73c813ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# path = os.getcwd()\n",
    "# print(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8cf93e90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "444\n",
      "num:\t 0\n",
      "num:\t 1\n",
      "num:\t 2\n",
      "Protein\n",
      " ['P0CG33' 'Q9NYA3' 'A6NDK9' 'Q5VT06' 'Q9C0D2' 'A6NDN3' 'Q8N3K9' 'H3BSY2'\n",
      " 'A8MQT2' 'Q8IYY4' 'A7E2F4' 'Q8WYP5' 'Q02952' 'Q8IYE1' 'H3BPF8' 'Q96SN8'\n",
      " 'P15311' 'Q9P219' 'Q6NUN7' 'O95613']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_21398/1986022666.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filter_features[\"Score\"] = filter_features[\"Score\"].astype(float)\n",
      "/tmp/ipykernel_21398/1986022666.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filter_features[\"Score\"] = filter_features[\"Score\"].round(2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num:\t 0\n",
      "num:\t 1\n",
      "num:\t 2\n",
      "Protein\n",
      " ['Q56NI9' 'Q8WYP5' 'O43663' 'P10243' 'P35251' 'O76021' 'Q69YH5' 'Q99741'\n",
      " 'Q9UPQ0' 'Q96T88' 'P46013' 'Q14680' 'Q14207' 'Q7RTP6' 'P10244' 'Q5UIP0'\n",
      " 'Q8NI77' 'P18583' 'Q86T82' 'Q12834']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_21398/1986022666.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filter_features[\"Score\"] = filter_features[\"Score\"].astype(float)\n",
      "/tmp/ipykernel_21398/1986022666.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filter_features[\"Score\"] = filter_features[\"Score\"].round(2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num:\t 0\n",
      "num:\t 1\n",
      "num:\t 2\n",
      "Protein\n",
      " ['Q56NI9' 'Q8WYP5' 'O43663' 'P35251' 'Q69YH5' 'Q99741' 'P46013' 'P10243'\n",
      " 'P10244' 'Q8NI77' 'Q14207' 'Q96T88' 'O76021' 'Q7RTP6' 'Q14680' 'Q8WWL7'\n",
      " 'P18583' 'Q9UPQ0' 'Q5UIP0' 'Q86T82']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_21398/1986022666.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filter_features[\"Score\"] = filter_features[\"Score\"].astype(float)\n",
      "/tmp/ipykernel_21398/1986022666.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filter_features[\"Score\"] = filter_features[\"Score\"].round(2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num:\t 0\n",
      "num:\t 1\n",
      "num:\t 2\n",
      "Protein\n",
      " ['Q08170' 'Q14498' 'Q13523' 'Q01130' 'P08621' 'Q14152' 'Q05519' 'Q13427'\n",
      " 'Q9Y2W1' 'Q13247' 'Q15696' 'Q9NQ29' 'Q5T200' 'Q86VM9' 'Q16629' 'Q96IZ7'\n",
      " 'O95232' 'Q9BRL6' 'O75494' 'P48634']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_21398/1986022666.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filter_features[\"Score\"] = filter_features[\"Score\"].astype(float)\n",
      "/tmp/ipykernel_21398/1986022666.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filter_features[\"Score\"] = filter_features[\"Score\"].round(2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num:\t 0\n",
      "num:\t 1\n",
      "num:\t 2\n",
      "Protein\n",
      " ['Q08170' 'Q14498' 'Q13523' 'Q01130' 'P08621' 'Q14152' 'Q05519' 'Q13427'\n",
      " 'Q9Y2W1' 'Q13247' 'Q15696' 'Q9NQ29' 'Q5T200' 'Q86VM9' 'Q16629' 'Q96IZ7'\n",
      " 'O95232' 'Q9BRL6' 'O75494' 'P48634']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "path = \"../statistics_data\"\n",
    "csv_files = glob.glob(os.path.join(path, \"*.csv\"))\n",
    "print(len(csv_files))\n",
    "  \n",
    "num = 0\n",
    "# loop over the list of csv files\n",
    "for f in csv_files:\n",
    "    \n",
    "    protein_filter = pd.DataFrame([])\n",
    "    filter_IDRs = pd.DataFrame([])\n",
    "    filter_features = pd.DataFrame([])\n",
    "    print(\"num:\\t\", num)\n",
    "    \n",
    "    # read the first csv file\n",
    "    if num == 0:\n",
    "        df_post_filename = f\n",
    "        num += 1\n",
    "    \n",
    "    # read the second csv file\n",
    "    elif num == 1:\n",
    "        df_pred_filename = f\n",
    "        num += 1\n",
    "        \n",
    "    # read the third csv file\n",
    "    else:\n",
    "        df_stat_filename = f\n",
    "        num = 0\n",
    "        \n",
    "        \n",
    "        # so far, read all files of one function\n",
    "        # print(\"Group:\\t\", df_post_filename, df_pred_filename, df_stat_filename, \"\\t\")\n",
    "        \n",
    "        # step1: protein\n",
    "        protein_file_name = df_pred_filename\n",
    "        # protein_cutoff_value = 0.15\n",
    "        # protein_filter = create_protein_filter_list(protein_file_name, protein_cutoff_value)\n",
    "        protein_filter = create_protein_filter_list(protein_file_name)\n",
    "        filtered_protein_name = protein_filter.index.values\n",
    "        print (\"Protein\\n\", filtered_protein_name)\n",
    "\n",
    "        # step2: IDRs\n",
    "        IDR_file_name = df_post_filename\n",
    "        IDR_cutoff_value1 = 0.5\n",
    "        IDR_cutoff_value2 = 0.6\n",
    "        html_filter_IDRs = create_IDR_filter_list(IDR_file_name, IDR_cutoff_value1, IDR_cutoff_value2, filtered_protein_name)\n",
    "        # print(\"IDR\\n\", filter_IDRs)\n",
    "\n",
    "        # step3: features\n",
    "        feature_file_name = df_stat_filename\n",
    "        html_filter_features = create_feature_filter_list(feature_file_name)\n",
    "        # print(\"Feature\\n\", filter_features)\n",
    "\n",
    "        # step4: HTML\n",
    "        function_name = df_pred_filename.split()[0]\n",
    "        function_name = function_name[:-1]\n",
    "        convert_to_HTML_format(html_filter_IDRs, html_filter_features, function_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09ba56b8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
